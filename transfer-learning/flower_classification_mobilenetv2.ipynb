{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "htRRmaibGIAJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "import PIL.Image as Image\n",
        "import os\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SHAPE = (224, 224)\n",
        "\n",
        "# classifier = tf.keras.Sequential([\n",
        "#     hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4\", input_shape=IMAGE_SHAPE + (3,))\n",
        "# ])"
      ],
      "metadata": {
        "id": "hPvWfy4bGQ9Y"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gold_fish = Image.open('goldfish.jpg').resize(IMAGE_SHAPE)\n",
        "# gold_fish"
      ],
      "metadata": {
        "id": "kXGKVx8OHQK9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gold_fish = np.array(gold_fish)/255.0\n",
        "# gold_fish.shape"
      ],
      "metadata": {
        "id": "7gQTAQLNH2JR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gold_fish"
      ],
      "metadata": {
        "id": "e50Ek2LoIOaN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gold_fish[np.newaxis, ...].shape"
      ],
      "metadata": {
        "id": "S2iuxxYnIRCj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# result = classifier.predict(gold_fish[np.newaxis, ...])\n",
        "# result.shape"
      ],
      "metadata": {
        "id": "QmJXjIfoId1m"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predicted_label_index = np.argmax(result)\n",
        "# predicted_label_index"
      ],
      "metadata": {
        "id": "JNeNqAISIkiC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# image_labels = []\n",
        "# with open(\"ImageNetLabels.txt\", \"r\") as f:\n",
        "#     image_labels = f.read().splitlines()\n",
        "# image_labels[:5]"
      ],
      "metadata": {
        "id": "5MY0qW8VI7vb"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# image_labels[predicted_label_index]"
      ],
      "metadata": {
        "id": "XWX8avsyJLAA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
        "data_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url,  cache_dir='.', untar=True)"
      ],
      "metadata": {
        "id": "SLU1qqrVJV4o"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "data_dir = pathlib.Path(data_dir)\n",
        "data_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwI64hKhJozx",
        "outputId": "64fb7675-7c94-4f0d-9b41-5df6ca5e7f07"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('datasets/flower_photos')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# list(data_dir.glob('*/*.jpg'))[:5]"
      ],
      "metadata": {
        "id": "8E42OezTJtgK"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "# print(image_count)"
      ],
      "metadata": {
        "id": "r9xckgxjJv9w"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# roses = list(data_dir.glob('roses/*'))\n",
        "# roses[:5]"
      ],
      "metadata": {
        "id": "WTf_r9wcJ_OR"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Image.open(str(roses[1]))"
      ],
      "metadata": {
        "id": "m-WhBz7tJyde"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tulips = list(data_dir.glob('tulips/*'))\n",
        "# Image.open(str(tulips[0]))"
      ],
      "metadata": {
        "id": "LGDs3SFZJ0Q4"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flowers_images_dict = {\n",
        "    'roses': list(data_dir.glob('roses/*')),\n",
        "    'daisy': list(data_dir.glob('daisy/*')),\n",
        "    'dandelion': list(data_dir.glob('dandelion/*')),\n",
        "    'sunflowers': list(data_dir.glob('sunflowers/*')),\n",
        "    'tulips': list(data_dir.glob('tulips/*')),\n",
        "}\n",
        "\n",
        "flowers_labels_dict = {\n",
        "    'roses': 0,\n",
        "    'daisy': 1,\n",
        "    'dandelion': 2,\n",
        "    'sunflowers': 3,\n",
        "    'tulips': 4,\n",
        "}"
      ],
      "metadata": {
        "id": "OC_OHGZaKFmc"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# flowers_images_dict['roses'][:5]"
      ],
      "metadata": {
        "id": "tohRtuK1KLDJ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "str(flowers_images_dict['roses'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "sIxp_jDwKOlZ",
        "outputId": "54bde47b-cd1c-420c-f4e0-24e084e955a4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'datasets/flower_photos/roses/15424480096_45bb574b33.jpg'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread(str(flowers_images_dict['roses'][0]))"
      ],
      "metadata": {
        "id": "c_CdLRnBKS1s"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# img.shape"
      ],
      "metadata": {
        "id": "P1yyu813KVeA"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cv2.resize(img,(224,224)).shape"
      ],
      "metadata": {
        "id": "Vehy6Xm6KXCN"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = [], []\n",
        "\n",
        "for flower_name, images in flowers_images_dict.items():\n",
        "    for image in images:\n",
        "        img = cv2.imread(str(image))\n",
        "        resized_img = cv2.resize(img,(224,224))\n",
        "        X.append(resized_img)\n",
        "        y.append(flowers_labels_dict[flower_name])"
      ],
      "metadata": {
        "id": "dswBHukMKZio"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(X)\n",
        "y = np.array(y)"
      ],
      "metadata": {
        "id": "LgrVb8H1Kbp7"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
      ],
      "metadata": {
        "id": "VsS3PrStKdsC"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled = X_train / 255\n",
        "X_test_scaled = X_test / 255"
      ],
      "metadata": {
        "id": "TZZMrgJaKgSY"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X[0].shape"
      ],
      "metadata": {
        "id": "FHXxXNJ-KiId"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# IMAGE_SHAPE+(3,)"
      ],
      "metadata": {
        "id": "3v7xHjpgKlsM"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x0_resized = cv2.resize(X[0], IMAGE_SHAPE)\n",
        "x1_resized = cv2.resize(X[1], IMAGE_SHAPE)\n",
        "x2_resized = cv2.resize(X[2], IMAGE_SHAPE)"
      ],
      "metadata": {
        "id": "p-kpcyRdKnVN"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.axis('off')\n",
        "# plt.imshow(X[0])"
      ],
      "metadata": {
        "id": "QCp_OOUIKpJm"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.axis('off')\n",
        "# plt.imshow(X[1])"
      ],
      "metadata": {
        "id": "_oV59HSyKq2i"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.axis('off')\n",
        "# plt.imshow(X[2])"
      ],
      "metadata": {
        "id": "VWiT2BZqKtE0"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predicted = classifier.predict(np.array([x0_resized, x1_resized, x2_resized]))\n",
        "# predicted = np.argmax(predicted, axis=1)\n",
        "# predicted"
      ],
      "metadata": {
        "id": "CxO0rrodKvO4"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# image_labels[795]"
      ],
      "metadata": {
        "id": "OS6xiRVWLq9b"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extractor_model = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
        "\n",
        "pretrained_model_without_top_layer = hub.KerasLayer(\n",
        "    feature_extractor_model, input_shape=(224,224,3),trainable=False\n",
        ")"
      ],
      "metadata": {
        "id": "-g99gRxYLvIk"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_of_flowers = 5\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    pretrained_model_without_top_layer,\n",
        "    tf.keras.layers.Dense(num_of_flowers)\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfJqayA9Mmrm",
        "outputId": "364d89f3-5115-45cb-f292-c80f6c7cc01b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " keras_layer (KerasLayer)    (None, 1280)              2257984   \n",
            "                                                                 \n",
            " dense (Dense)               (None, 5)                 6405      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2264389 (8.64 MB)\n",
            "Trainable params: 6405 (25.02 KB)\n",
            "Non-trainable params: 2257984 (8.61 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "  optimizer=\"adam\",\n",
        "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['acc'])\n",
        "\n",
        "model.fit(X_train_scaled, y_train, epochs=5)"
      ],
      "metadata": {
        "id": "DayLoEnJMxAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test_scaled,y_test)"
      ],
      "metadata": {
        "id": "DZ3k3RK7O4ue"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}